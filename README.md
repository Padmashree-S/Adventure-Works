Azure Data Pipeline: Automated, Scalable & Real-Time Analytics 🚀
📌 Project Overview
This project builds a fully automated and scalable Azure Data Pipeline to ingest, transform, and analyze data efficiently. It cuts down processing time by 70%, enables real-time insights, and ensures secure and scalable data management.

⚡ Key Features
✅ Automated Ingestion – Pulls CSV data dynamically from GitHub using Azure Data Factory (ADF).
✅ Advanced Data Transformation – Cleans & enriches data using Azure Databricks (Apache Spark).
✅ Optimized Storage – Stores structured data in Azure Synapse Analytics (partitioned & indexed).
✅ Data Visualization – Power BI dashboards for instant insights.

🔧 Tech Stack
Azure Services: Data Factory, Databricks, Synapse Analytics

Storage: Azure Data Lake (Parquet format)

Infrastructure as Code: GitHub Actions

Visualization: Power BI

Programming: PySpark, SQL

🛠️ Architecture Overview
1️⃣ Ingest data – ADF pulls CSV files from GitHub API into Azure Data Lake (Bronze Layer).
2️⃣ Transform & clean – Databricks processes data (Silver Layer) for efficiency.
3️⃣ Store & optimize – Synapse Analytics (Gold Layer) for fast analytics.
4️⃣ Visualize insights – Power BI dashboards for real-time analytics. 
